{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency Inverse Document Frequency (tf-idf)\n",
    "\n",
    "* Rescale features by how informative we expect them to be\n",
    "* Give weight to any term that appears often in a particular document, but not in many documents\n",
    "* TfidfVectorizer takes the text data and does both the bag-of-words feature extraction and tf-idf transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse:\n",
      "\n",
      "   (0, 3)\t0.8610369959439764\n",
      "  (0, 4)\t0.5085423203783267\n",
      "  (1, 1)\t0.652490884512534\n",
      "  (1, 2)\t0.652490884512534\n",
      "  (1, 4)\t0.3853716274664007\n",
      "  (2, 5)\t0.652490884512534\n",
      "  (2, 0)\t0.652490884512534\n",
      "  (2, 4)\t0.3853716274664007\n",
      "\n",
      "Dense:\n",
      "\n",
      " [[0.         0.         0.         0.861037   0.50854232 0.        ]\n",
      " [0.         0.65249088 0.65249088 0.         0.38537163 0.        ]\n",
      " [0.65249088 0.         0.         0.         0.38537163 0.65249088]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"words\": [\"Sola runs\", \"Sola is a dog\", \"Sola chews toys\"]\n",
    "})\n",
    "\n",
    "# TfidfVectorizer takes hyperparameters such as:\n",
    "#  min_df=0.1\n",
    "#  max_df=0.75\n",
    "#  max_features=50\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# X here is a sparse matrix with one row per document and one column per \n",
    "# unique word in the corpus (all the words in all the documents)\n",
    "X = vectorizer.fit_transform(df[\"words\"])\n",
    "\n",
    "print(\"Sparse:\\n\\n\", X)\n",
    "\n",
    "print(\"\\nDense:\\n\\n\", X.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which columns represent which words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chews', 'dog', 'is', 'runs', 'sola', 'toys']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see, for example, that the first row (representing \"Sola runs\") has values in the \"runs\" and \"Sola\" columns.\n",
    "# Together these let us construct a data frame if we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chews</th>\n",
       "      <th>dog</th>\n",
       "      <th>is</th>\n",
       "      <th>runs</th>\n",
       "      <th>sola</th>\n",
       "      <th>toys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.861037</td>\n",
       "      <td>0.508542</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.652491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      chews       dog        is      runs      sola      toys\n",
       "0  0.000000  0.000000  0.000000  0.861037  0.508542  0.000000\n",
       "1  0.000000  0.652491  0.652491  0.000000  0.385372  0.000000\n",
       "2  0.652491  0.000000  0.000000  0.000000  0.385372  0.652491"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the vocabulary\n",
    "\n",
    "The attribute vocabulary_ outputs a dictionary in which all ngrams are the dictionary keys and the respective values are the column positions of each ngram (feature) in the tfidf matrix. [#](https://stackoverflow.com/a/54338182/156835)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sola': 4, 'runs': 3, 'is': 2, 'dog': 1, 'chews': 0, 'toys': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 'sola', 3: 'runs', 2: 'is', 1: 'dog', 0: 'chews', 5: 'toys'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can swap the keys and values to map the column number to the word:\n",
    "\n",
    "vocab = {v:k for k, v in vectorizer.vocabulary_.items()}\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing document data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t0.8610369959439764\n",
      "  (0, 4)\t0.5085423203783267\n",
      "  (1, 1)\t0.652490884512534\n",
      "  (1, 2)\t0.652490884512534\n",
      "  (1, 4)\t0.3853716274664007\n",
      "  (2, 5)\t0.652490884512534\n",
      "  (2, 0)\t0.652490884512534\n",
      "  (2, 4)\t0.3853716274664007\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "# For any given document, we can access the word indices and tf-idt weights:\n",
    "print(X[0].indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.861037   0.50854232]\n"
     ]
    }
   ],
   "source": [
    "# And the data:\n",
    "print(X[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0.8610369959439764, 4: 0.5085423203783267}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can zip these together and convert them into a dict:\n",
    "dict(zip(X[0].indices, X[0].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering a tf-idf vector\n",
    "\n",
    "The problem with the tf-idf vector is that it may contain thousands of words depending on the size of the corpus.\n",
    "\n",
    "We don't want to train a model on using all of those features (the words). Instead, we can identify the most top_n most important terms in each document and then filter the tf-idf vector so it only contains the columns for terms that are in the top_n for any of the documents.\n",
    "\n",
    "This code is inspired via DataCamp's Selecting Features for Modeling course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the indeces of the top_n terms in a given row.\n",
    "def return_indeces_of_top_terms_in_document(vocab, original_vocab, vector, vector_index, top_n):\n",
    "    zipped = dict(zip(vector[vector_index].indices, vector[vector_index].data))\n",
    "    zipped_series = pd.Series({vocab[i]:zipped[i] for i in vector[vector_index].indices})\n",
    "    zipped_index = zipped_series.sort_values(ascending=False)[:top_n].index\n",
    "    return [original_vocab[i] for i in zipped_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For example:\n",
    "return_indeces_of_top_terms_in_document(vocab, vectorizer.vocabulary_, X, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns 3 because in the first row (index 0), we're looking at the top 1 weight, which is 0.861037, which is in the fourth column (index 3).\n",
    "\n",
    "If instead we looked at the top 2 terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_indeces_of_top_terms_in_document(vocab, vectorizer.vocabulary_, X, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the two terms (Sola and runs) are in the fourth and fifth columns (index 3 and 4).\n",
    "\n",
    "The second column has a tie in weights between dog and is (both have a weight of 0.652491) but sort_values winds up putting dog first for some reason, so this returns index 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_indeces_of_top_terms_in_document(vocab, vectorizer.vocabulary_, X, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, we can iterate over all of the rows (documents) and determine the top_n words. return_top_term_indeces returns their indeces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_term_indeces(vocab, original_vocab, vector, top_n):\n",
    "    filter_list = []\n",
    "    for i in range(0, vector.shape[0]):\n",
    "        filtered = return_indeces_of_top_terms_in_document(vocab, original_vocab, vector, i, top_n)\n",
    "        filter_list.extend(filtered)\n",
    "\n",
    "    return set(filter_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we specify top_n is 1, then it iterates over each row and grabs the index for the highest weighted term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 3}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeces = return_top_term_indeces(vocab, vectorizer.vocabulary_, X, 1)\n",
    "indeces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a set of {0, 2, 3} because the in row 1 the highest weighted term is at index 3 (Sola), row 2 at index 2 (dog), row 3 at index 0 (chews).\n",
    "\n",
    "Then we can filter the original vector down to just these important terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.861037  ]\n",
      " [0.         0.65249088 0.        ]\n",
      " [0.65249088 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X_filtered = X[:, list(indeces)]\n",
    "print(X_filtered.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame:\n",
      "      chews       dog        is      runs      sola      toys\n",
      "0  0.000000  0.000000  0.000000  0.861037  0.508542  0.000000\n",
      "1  0.000000  0.652491  0.652491  0.000000  0.385372  0.000000\n",
      "2  0.652491  0.000000  0.000000  0.000000  0.385372  0.652491\n",
      "\n",
      "Values:\n",
      "[[0.         0.         0.         0.861037   0.50854232 0.        ]\n",
      " [0.         0.65249088 0.65249088 0.         0.38537163 0.        ]\n",
      " [0.65249088 0.         0.         0.         0.38537163 0.65249088]]\n",
      "\n",
      "Filtered values:\n",
      "[[0.         0.         0.861037  ]\n",
      " [0.         0.65249088 0.        ]\n",
      " [0.65249088 0.         0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def return_indeces_of_top_terms_in_document(vocab, original_vocab, vector, vector_index, top_n):\n",
    "    zipped = dict(zip(vector[vector_index].indices, vector[vector_index].data))    \n",
    "    zipped_series = pd.Series({vocab[i]:zipped[i] for i in vector[vector_index].indices})\n",
    "    zipped_index = zipped_series.sort_values(ascending=False)[:top_n].index\n",
    "    return [original_vocab[i] for i in zipped_index]\n",
    "\n",
    "def return_top_term_indeces(vocab, original_vocab, vector, top_n):\n",
    "    filter_list = []\n",
    "    for i in range(0, vector.shape[0]):    \n",
    "        filtered = return_indeces_of_top_terms_in_document(vocab, original_vocab, vector, i, top_n)\n",
    "        filter_list.extend(filtered)\n",
    "    return set(filter_list)\n",
    "\n",
    "def select_highest_weighted_terms(vectorizer, X, top_n):\n",
    "    vocab = {v:k for k, v in vectorizer.vocabulary_.items()}\n",
    "\n",
    "    indeces = return_top_term_indeces(vocab, vectorizer.vocabulary_, X, 1)\n",
    "    return X[:, list(indeces)]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"words\": [\"Sola runs\", \"Sola is a dog\", \"Sola chews toys\"]\n",
    "})\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"words\"])\n",
    "\n",
    "print(\"Data Frame:\\n{}\\n\".format(pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())))\n",
    "print(\"Values:\\n{}\\n\".format(X.todense()))\n",
    "\n",
    "X_filtered = select_highest_weighted_terms(vectorizer, X, 1)\n",
    "print(\"Filtered values:\\n{}\\n\".format(X_filtered.todense()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
