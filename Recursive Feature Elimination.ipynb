{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination (RFE)\n",
    "\n",
    "RFE is a technique for iteratively removing features that have the least impact on the model (ie have the lowest coefficients).\n",
    "\n",
    "From the docs:\n",
    "\n",
    "> Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "\n",
    "Resources:\n",
    "\n",
    "* [Dimensionality Reduction in Python](https://campus.datacamp.com/courses/dimensionality-reduction-in-python/feature-selection-ii-selecting-for-model-accuracy)\n",
    "* [RFE Docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/titantic-train.csv\").dropna()\n",
    "y = df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default score and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.69\n",
      "Coefficients: {'Age': 0.75, 'Fare': 0.47, 'Pclass': 0.23, 'SibSp': 0.12, 'Parch': 0.38}\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"Age\", \"Fare\", \"Pclass\", \"SibSp\", \"Parch\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy score: {:.2f}\".format(accuracy_score(y_test, lr.predict(X_test_scaled))))\n",
    "print(\"Coefficients:\", dict(zip(X.columns, abs(lr.coef_[0]).round(2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after removing feature with lowest coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.69\n",
      "Coefficients: {'Age': 0.76, 'Fare': 0.51, 'Pclass': 0.24, 'Parch': 0.38}\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"Age\", \"Fare\", \"Pclass\", \"Parch\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy score: {:.2f}\".format(accuracy_score(y_test, lr.predict(X_test_scaled))))\n",
    "print(\"Coefficients:\", dict(zip(X.columns, abs(lr.coef_[0]).round(2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RFE to remove low importance features automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 5 features.\n",
      "\n",
      "Rankings: {'Age': 1, 'Fare': 1, 'Pclass': 1, 'SibSp': 2, 'Parch': 1}\n",
      "Selected features: ['Age' 'Fare' 'Pclass' 'Parch']\n",
      "Accuracy score: 0.69\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"Age\", \"Fare\", \"Pclass\", \"SibSp\", \"Parch\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Can also set a step parameter to have it remove multiple features in each step, not just 1\n",
    "# which can improve performance\n",
    "rfe = RFE(lr, n_features_to_select=4, verbose=1)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the features and their ranking (high = dropped early on)\n",
    "print(\"\\nRankings:\", dict(zip(X.columns, rfe.ranking_)))\n",
    "print(\"Selected features:\", X.columns[rfe.support_].values)\n",
    "print(\"Accuracy score: {:.2f}\".format(accuracy_score(y_test, rfe.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.80\n",
      "Feature importances: {'Age': 0.45, 'Fare': 0.39, 'Pclass': 0.04, 'SibSp': 0.05, 'Parch': 0.07}\n",
      "Reduced features: ['Age' 'Fare']\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"Age\", \"Fare\", \"Pclass\", \"SibSp\", \"Parch\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=3)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy score: {:.2f}\".format(accuracy_score(y_test, rf.predict(X_test))))\n",
    "print(\"Feature importances:\", dict(zip(X.columns, rf.feature_importances_.round(2))))\n",
    "\n",
    "mask = rf.feature_importances_ > 0.10\n",
    "reduced_features = X.loc[:, mask]\n",
    "print(\"Reduced features:\", reduced_features.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RFE to remove low importance features automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "\n",
      "Rankings: {'Age': 1, 'Fare': 1, 'Pclass': 4, 'SibSp': 2, 'Parch': 3}\n",
      "Selected features: ['Age' 'Fare']\n",
      "Accuracy score: 0.78\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"Age\", \"Fare\", \"Pclass\", \"SibSp\", \"Parch\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=3)\n",
    "rfe = RFE(rf, n_features_to_select=2, verbose=1)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nRankings:\", dict(zip(X.columns, rfe.ranking_)))\n",
    "print(\"Selected features:\", X.columns[rfe.support_].values)\n",
    "print(\"Accuracy score: {:.2f}\".format(accuracy_score(y_test, rfe.predict(X_test))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
