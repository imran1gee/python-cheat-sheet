{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "import warnings\n",
    "# To avoid a `optional dependency `torch` is not available` warning with tpot\n",
    "warnings.simplefilter('ignore')\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/titantic-train.csv\")\n",
    "df = df[[\"Fare\", \"Age\", \"Pclass\", \"SibSp\", \"Parch\", \"Survived\"]].dropna()\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1:].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Fitting and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf.score: 0.67\n",
      "accuracy_score: 0.67\n",
      "cross_val_score: 0.68\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# score and accuracy_score measure the same metric but in different ways\n",
    "print(\"rf.score: {:.2f}\".format(rf.score(X_test, y_test)))\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"accuracy_score: {:.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(\"cross_val_score: {:.2f}\".format(cross_val_score(rf, X, y).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bests parameters: {'max_depth': 5, 'n_estimators': 125}\n",
      "Best score: 0.74\n",
      "Cross val score: 0.68\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(50, 200, 25),\n",
    "    'max_depth': range(2, 8)\n",
    "}\n",
    "\n",
    "rf_cv = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Bests parameters: {}\".format(rf_cv.best_params_)) \n",
    "print(\"Best score: {:.2f}\".format(rf_cv.best_score_))\n",
    "print(\"Cross val score: {:.2f}\".format(cross_val_score(rf_cv, X_test, y_test).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting grid search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130654</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.012664</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 50}</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.689720</td>\n",
       "      <td>0.029789</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200543</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 75}</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.689720</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282160</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 100}</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.356142</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>0.024831</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 125}</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.687850</td>\n",
       "      <td>0.032158</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449668</td>\n",
       "      <td>0.017736</td>\n",
       "      <td>0.043828</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 150}</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.695327</td>\n",
       "      <td>0.024797</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.562337</td>\n",
       "      <td>0.016077</td>\n",
       "      <td>0.030346</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 175}</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.695327</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.156361</td>\n",
       "      <td>0.023407</td>\n",
       "      <td>0.013681</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 50}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.725234</td>\n",
       "      <td>0.036244</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.187256</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.016141</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 75}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.727103</td>\n",
       "      <td>0.033122</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.259037</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>0.019546</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.727103</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.303846</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.022308</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 125}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.727103</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.364042</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.027164</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 150}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.727103</td>\n",
       "      <td>0.033122</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.417173</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 175}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.122708</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 50}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.045402</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.201539</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 75}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.730841</td>\n",
       "      <td>0.048526</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.247195</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.018278</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.730841</td>\n",
       "      <td>0.049594</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.295207</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 125}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.730841</td>\n",
       "      <td>0.049594</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.363745</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 150}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.734579</td>\n",
       "      <td>0.051052</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.427416</td>\n",
       "      <td>0.013036</td>\n",
       "      <td>0.028865</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 175}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.730841</td>\n",
       "      <td>0.048165</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.127576</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.730841</td>\n",
       "      <td>0.049945</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.199690</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 75}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>0.056509</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.246159</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.018243</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>0.051665</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.301505</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.023240</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 125}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.055322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.371282</td>\n",
       "      <td>0.017159</td>\n",
       "      <td>0.024345</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 150}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.734579</td>\n",
       "      <td>0.053066</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.435220</td>\n",
       "      <td>0.014439</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 175}</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.730841</td>\n",
       "      <td>0.052669</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.125717</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>0.011999</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 50}</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>0.061256</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.185888</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 75}</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.740187</td>\n",
       "      <td>0.053328</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.248110</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 100}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.053850</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.314723</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 125}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.051529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.375178</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 150}</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.732710</td>\n",
       "      <td>0.055950</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.441891</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.038637</td>\n",
       "      <td>0.013063</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 175}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.057611</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.131213</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 50}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.045015</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.204628</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 75}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>0.053980</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.249594</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.019843</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 100}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.051867</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.322396</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 125}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.734579</td>\n",
       "      <td>0.051052</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.383716</td>\n",
       "      <td>0.011144</td>\n",
       "      <td>0.026599</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 150}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>0.050984</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.344872</td>\n",
       "      <td>0.035768</td>\n",
       "      <td>0.019572</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>7</td>\n",
       "      <td>175</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 175}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>0.050640</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.130654      0.001870         0.012664        0.001354   \n",
       "1        0.200543      0.007618         0.016523        0.001274   \n",
       "2        0.282160      0.008168         0.022606        0.003857   \n",
       "3        0.356142      0.012887         0.024831        0.001657   \n",
       "4        0.449668      0.017736         0.043828        0.009241   \n",
       "5        0.562337      0.016077         0.030346        0.002007   \n",
       "6        0.156361      0.023407         0.013681        0.004258   \n",
       "7        0.187256      0.002807         0.016141        0.002406   \n",
       "8        0.259037      0.007344         0.019546        0.002810   \n",
       "9        0.303846      0.015269         0.022308        0.002768   \n",
       "10       0.364042      0.007525         0.027164        0.002500   \n",
       "11       0.417173      0.007832         0.035655        0.008824   \n",
       "12       0.122708      0.004293         0.011535        0.003222   \n",
       "13       0.201539      0.006234         0.014174        0.000245   \n",
       "14       0.247195      0.008261         0.018278        0.002078   \n",
       "15       0.295207      0.009709         0.025946        0.006819   \n",
       "16       0.363745      0.004636         0.027828        0.003523   \n",
       "17       0.427416      0.013036         0.028865        0.002729   \n",
       "18       0.127576      0.010962         0.010149        0.000245   \n",
       "19       0.199690      0.005943         0.016415        0.002543   \n",
       "20       0.246159      0.003056         0.018243        0.001529   \n",
       "21       0.301505      0.014152         0.023240        0.002797   \n",
       "22       0.371282      0.017159         0.024345        0.001257   \n",
       "23       0.435220      0.014439         0.031924        0.002570   \n",
       "24       0.125717      0.006125         0.011999        0.001750   \n",
       "25       0.185888      0.004171         0.015278        0.001988   \n",
       "26       0.248110      0.005036         0.019650        0.003145   \n",
       "27       0.314723      0.006142         0.022033        0.002104   \n",
       "28       0.375178      0.007305         0.026828        0.002441   \n",
       "29       0.441891      0.010533         0.038637        0.013063   \n",
       "30       0.131213      0.005680         0.010729        0.000634   \n",
       "31       0.204628      0.011364         0.017935        0.007719   \n",
       "32       0.249594      0.009276         0.019843        0.002749   \n",
       "33       0.322396      0.007699         0.022356        0.002415   \n",
       "34       0.383716      0.011144         0.026599        0.001842   \n",
       "35       0.344872      0.035768         0.019572        0.004392   \n",
       "\n",
       "   param_max_depth param_n_estimators                                 params  \\\n",
       "0                2                 50   {'max_depth': 2, 'n_estimators': 50}   \n",
       "1                2                 75   {'max_depth': 2, 'n_estimators': 75}   \n",
       "2                2                100  {'max_depth': 2, 'n_estimators': 100}   \n",
       "3                2                125  {'max_depth': 2, 'n_estimators': 125}   \n",
       "4                2                150  {'max_depth': 2, 'n_estimators': 150}   \n",
       "5                2                175  {'max_depth': 2, 'n_estimators': 175}   \n",
       "6                3                 50   {'max_depth': 3, 'n_estimators': 50}   \n",
       "7                3                 75   {'max_depth': 3, 'n_estimators': 75}   \n",
       "8                3                100  {'max_depth': 3, 'n_estimators': 100}   \n",
       "9                3                125  {'max_depth': 3, 'n_estimators': 125}   \n",
       "10               3                150  {'max_depth': 3, 'n_estimators': 150}   \n",
       "11               3                175  {'max_depth': 3, 'n_estimators': 175}   \n",
       "12               4                 50   {'max_depth': 4, 'n_estimators': 50}   \n",
       "13               4                 75   {'max_depth': 4, 'n_estimators': 75}   \n",
       "14               4                100  {'max_depth': 4, 'n_estimators': 100}   \n",
       "15               4                125  {'max_depth': 4, 'n_estimators': 125}   \n",
       "16               4                150  {'max_depth': 4, 'n_estimators': 150}   \n",
       "17               4                175  {'max_depth': 4, 'n_estimators': 175}   \n",
       "18               5                 50   {'max_depth': 5, 'n_estimators': 50}   \n",
       "19               5                 75   {'max_depth': 5, 'n_estimators': 75}   \n",
       "20               5                100  {'max_depth': 5, 'n_estimators': 100}   \n",
       "21               5                125  {'max_depth': 5, 'n_estimators': 125}   \n",
       "22               5                150  {'max_depth': 5, 'n_estimators': 150}   \n",
       "23               5                175  {'max_depth': 5, 'n_estimators': 175}   \n",
       "24               6                 50   {'max_depth': 6, 'n_estimators': 50}   \n",
       "25               6                 75   {'max_depth': 6, 'n_estimators': 75}   \n",
       "26               6                100  {'max_depth': 6, 'n_estimators': 100}   \n",
       "27               6                125  {'max_depth': 6, 'n_estimators': 125}   \n",
       "28               6                150  {'max_depth': 6, 'n_estimators': 150}   \n",
       "29               6                175  {'max_depth': 6, 'n_estimators': 175}   \n",
       "30               7                 50   {'max_depth': 7, 'n_estimators': 50}   \n",
       "31               7                 75   {'max_depth': 7, 'n_estimators': 75}   \n",
       "32               7                100  {'max_depth': 7, 'n_estimators': 100}   \n",
       "33               7                125  {'max_depth': 7, 'n_estimators': 125}   \n",
       "34               7                150  {'max_depth': 7, 'n_estimators': 150}   \n",
       "35               7                175  {'max_depth': 7, 'n_estimators': 175}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.682243           0.635514           0.710280   \n",
       "1            0.682243           0.635514           0.710280   \n",
       "2            0.682243           0.644860           0.710280   \n",
       "3            0.672897           0.635514           0.710280   \n",
       "4            0.691589           0.654206           0.710280   \n",
       "5            0.691589           0.644860           0.710280   \n",
       "6            0.719626           0.663551           0.728972   \n",
       "7            0.719626           0.672897           0.728972   \n",
       "8            0.719626           0.663551           0.728972   \n",
       "9            0.719626           0.663551           0.728972   \n",
       "10           0.719626           0.672897           0.728972   \n",
       "11           0.719626           0.672897           0.728972   \n",
       "12           0.719626           0.654206           0.719626   \n",
       "13           0.719626           0.644860           0.738318   \n",
       "14           0.719626           0.644860           0.738318   \n",
       "15           0.719626           0.644860           0.738318   \n",
       "16           0.719626           0.644860           0.747664   \n",
       "17           0.728972           0.644860           0.728972   \n",
       "18           0.728972           0.644860           0.719626   \n",
       "19           0.728972           0.635514           0.738318   \n",
       "20           0.728972           0.644860           0.738318   \n",
       "21           0.728972           0.644860           0.747664   \n",
       "22           0.719626           0.644860           0.738318   \n",
       "23           0.710280           0.644860           0.738318   \n",
       "24           0.700935           0.635514           0.757009   \n",
       "25           0.710280           0.654206           0.747664   \n",
       "26           0.719626           0.644860           0.747664   \n",
       "27           0.728972           0.644860           0.747664   \n",
       "28           0.710280           0.635514           0.747664   \n",
       "29           0.719626           0.635514           0.757009   \n",
       "30           0.719626           0.644860           0.757009   \n",
       "31           0.728972           0.635514           0.757009   \n",
       "32           0.728972           0.644860           0.747664   \n",
       "33           0.719626           0.644860           0.747664   \n",
       "34           0.719626           0.644860           0.757009   \n",
       "35           0.719626           0.644860           0.766355   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.700935           0.719626         0.689720        0.029789   \n",
       "1            0.691589           0.728972         0.689720        0.031500   \n",
       "2            0.691589           0.728972         0.691589        0.028347   \n",
       "3            0.691589           0.728972         0.687850        0.032158   \n",
       "4            0.691589           0.728972         0.695327        0.024797   \n",
       "5            0.700935           0.728972         0.695327        0.028100   \n",
       "6            0.738318           0.775701         0.725234        0.036244   \n",
       "7            0.738318           0.775701         0.727103        0.033122   \n",
       "8            0.738318           0.785047         0.727103        0.038940   \n",
       "9            0.738318           0.785047         0.727103        0.038940   \n",
       "10           0.738318           0.775701         0.727103        0.033122   \n",
       "11           0.738318           0.785047         0.728972        0.035954   \n",
       "12           0.766355           0.785047         0.728972        0.045402   \n",
       "13           0.766355           0.785047         0.730841        0.048526   \n",
       "14           0.757009           0.794393         0.730841        0.049594   \n",
       "15           0.757009           0.794393         0.730841        0.049594   \n",
       "16           0.766355           0.794393         0.734579        0.051052   \n",
       "17           0.766355           0.785047         0.730841        0.048165   \n",
       "18           0.775701           0.785047         0.730841        0.049945   \n",
       "19           0.785047           0.794393         0.736449        0.056509   \n",
       "20           0.775701           0.794393         0.736449        0.051665   \n",
       "21           0.785047           0.803738         0.742056        0.055322   \n",
       "22           0.766355           0.803738         0.734579        0.053066   \n",
       "23           0.757009           0.803738         0.730841        0.052669   \n",
       "24           0.785047           0.803738         0.736449        0.061256   \n",
       "25           0.794393           0.794393         0.740187        0.053328   \n",
       "26           0.794393           0.785047         0.738318        0.053850   \n",
       "27           0.785047           0.785047         0.738318        0.051529   \n",
       "28           0.785047           0.785047         0.732710        0.055950   \n",
       "29           0.785047           0.794393         0.738318        0.057611   \n",
       "30           0.766355           0.757009         0.728972        0.045015   \n",
       "31           0.785047           0.775701         0.736449        0.053980   \n",
       "32           0.794393           0.775701         0.738318        0.051867   \n",
       "33           0.794393           0.766355         0.734579        0.051052   \n",
       "34           0.785047           0.775701         0.736449        0.050984   \n",
       "35           0.785047           0.766355         0.736449        0.050640   \n",
       "\n",
       "    rank_test_score  \n",
       "0                34  \n",
       "1                35  \n",
       "2                33  \n",
       "3                36  \n",
       "4                32  \n",
       "5                31  \n",
       "6                30  \n",
       "7                28  \n",
       "8                26  \n",
       "9                26  \n",
       "10               28  \n",
       "11               25  \n",
       "12               23  \n",
       "13               18  \n",
       "14               18  \n",
       "15               18  \n",
       "16               13  \n",
       "17               18  \n",
       "18               17  \n",
       "19               10  \n",
       "20               10  \n",
       "21                1  \n",
       "22               14  \n",
       "23               18  \n",
       "24                7  \n",
       "25                2  \n",
       "26                5  \n",
       "27                3  \n",
       "28               16  \n",
       "29                6  \n",
       "30               23  \n",
       "31                7  \n",
       "32                3  \n",
       "33               14  \n",
       "34                7  \n",
       "35               10  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bests parameters: {'n_estimators': 425, 'max_depth': 7}\n",
      "Best score: 0.74\n",
      "Cross val score: 0.70\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(50, 500, 25),\n",
    "    'max_depth': range(2, 20)\n",
    "}\n",
    "\n",
    "# n_iter (number of iterations) is the number of sampled combinations of hyperparameters\n",
    "rf_cv = RandomizedSearchCV(rf, param_grid, random_state=1, n_iter=50, cv=5, n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Bests parameters: {}\".format(rf_cv.best_params_)) \n",
    "print(\"Best score: {:.2f}\".format(rf_cv.best_score_))\n",
    "print(\"Cross val score: {:.2f}\".format(cross_val_score(rf_cv, X_test, y_test).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130268</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 7}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.045015</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.388667</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>150</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 7}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>0.050984</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.382457</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.027185</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 6}</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.732710</td>\n",
       "      <td>0.055950</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.305021</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 125, 'max_depth': 2}</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.687850</td>\n",
       "      <td>0.032158</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.180069</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_estimators': 75, 'max_depth': 5}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736449</td>\n",
       "      <td>0.056509</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.423250</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.032053</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>175</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 4}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.730841</td>\n",
       "      <td>0.048165</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.312617</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_estimators': 125, 'max_depth': 5}</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.055322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.425931</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.032333</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 5}</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.730841</td>\n",
       "      <td>0.052669</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.413318</td>\n",
       "      <td>0.025789</td>\n",
       "      <td>0.024067</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 175, 'max_depth': 6}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.057611</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.223631</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 6}</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.053850</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.130268      0.003439         0.011136        0.000766   \n",
       "1       0.388667      0.002007         0.033691        0.005079   \n",
       "2       0.382457      0.006916         0.027185        0.001697   \n",
       "3       0.305021      0.003446         0.021309        0.000973   \n",
       "4       0.180069      0.006781         0.014556        0.001605   \n",
       "5       0.423250      0.006835         0.032053        0.004332   \n",
       "6       0.312617      0.003313         0.023859        0.004497   \n",
       "7       0.425931      0.009402         0.032333        0.001836   \n",
       "8       0.413318      0.025789         0.024067        0.006235   \n",
       "9       0.223631      0.029920         0.014834        0.003641   \n",
       "\n",
       "  param_n_estimators param_max_depth                                 params  \\\n",
       "0                 50               7   {'n_estimators': 50, 'max_depth': 7}   \n",
       "1                150               7  {'n_estimators': 150, 'max_depth': 7}   \n",
       "2                150               6  {'n_estimators': 150, 'max_depth': 6}   \n",
       "3                125               2  {'n_estimators': 125, 'max_depth': 2}   \n",
       "4                 75               5   {'n_estimators': 75, 'max_depth': 5}   \n",
       "5                175               4  {'n_estimators': 175, 'max_depth': 4}   \n",
       "6                125               5  {'n_estimators': 125, 'max_depth': 5}   \n",
       "7                175               5  {'n_estimators': 175, 'max_depth': 5}   \n",
       "8                175               6  {'n_estimators': 175, 'max_depth': 6}   \n",
       "9                100               6  {'n_estimators': 100, 'max_depth': 6}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.719626           0.644860           0.757009           0.766355   \n",
       "1           0.719626           0.644860           0.757009           0.785047   \n",
       "2           0.710280           0.635514           0.747664           0.785047   \n",
       "3           0.672897           0.635514           0.710280           0.691589   \n",
       "4           0.728972           0.635514           0.738318           0.785047   \n",
       "5           0.728972           0.644860           0.728972           0.766355   \n",
       "6           0.728972           0.644860           0.747664           0.785047   \n",
       "7           0.710280           0.644860           0.738318           0.757009   \n",
       "8           0.719626           0.635514           0.757009           0.785047   \n",
       "9           0.719626           0.644860           0.747664           0.794393   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.757009         0.728972        0.045015                9  \n",
       "1           0.775701         0.736449        0.050984                4  \n",
       "2           0.785047         0.732710        0.055950                6  \n",
       "3           0.728972         0.687850        0.032158               10  \n",
       "4           0.794393         0.736449        0.056509                5  \n",
       "5           0.785047         0.730841        0.048165                7  \n",
       "6           0.803738         0.742056        0.055322                1  \n",
       "7           0.803738         0.730841        0.052669                7  \n",
       "8           0.794393         0.738318        0.057611                3  \n",
       "9           0.785047         0.738318        0.053850                2  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rf_cv.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing distribution of accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(rf_cv.cv_results_['mean_test_score'], hist=True, kde=True)\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Occurrences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the impact of hyperparameter values on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=rf_cv.cv_results_, x=\"param_max_depth\", y=\"mean_test_score\")\n",
    "plt.title(\"Accuracy for different max depths\")\n",
    "plt.xlabel(\"max depth\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=rf_cv.cv_results_, x=\"param_n_estimators\", y=\"mean_test_score\")\n",
    "plt.title(\"Accuracy for different numbers of estimators\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these scatter plots showed patterns where certain values clearly outperformed others, we could use it to inform a grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search with named steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bests parameters: {'SVM__C': 100, 'SVM__gamma': 0.01}\n",
      "Best score: 0.75\n",
      "Cross val score: 0.65\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), ('SVM', SVC())])\n",
    "param_grid = {\n",
    "    'SVM__C': [1, 10, 100],\n",
    "    'SVM__gamma': [0.1, 0.01]\n",
    "}\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Bests parameters: {}\".format(grid.best_params_)) \n",
    "print(\"Best score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Cross val score: {:.2f}\".format(cross_val_score(grid, X_test, y_test).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search without named steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bests parameters: {'svc__C': 100, 'svc__gamma': 0.01}\n",
      "Best score: 0.75\n",
      "Cross val score: 0.65\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), SVC())\n",
    "param_grid = {\n",
    "    \"svc__C\": [1, 10, 100],\n",
    "    \"svc__gamma\": [0.1, 0.01]\n",
    "}\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Bests parameters: {}\".format(grid.best_params_)) \n",
    "print(\"Best score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Cross val score: {:.2f}\".format(cross_val_score(grid, X_test, y_test).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Hyperparameter Tuning\n",
    "\n",
    "References:\n",
    "\n",
    "* [Hyperparameter Tuning in Python](https://campus.datacamp.com/courses/hyperparameter-tuning-in-python/informed-search?ex=6)\n",
    "* [Part 2: Hyperopt.](https://towardsdatascience.com/hyperparameter-optimization-in-python-part-2-hyperopt-5f661db91324)\n",
    "* [Hyperopt FMin docs](https://github.com/hyperopt/hyperopt/wiki/FMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:08<00:00,  2.34trial/s, best loss: 0.26531667505170775]\n",
      "{'max_depth': 4.0, 'n_estimators': 172.0}\n"
     ]
    }
   ],
   "source": [
    "# We need to define two things:\n",
    "\n",
    "# 1. The search space\n",
    "space = {\n",
    "    \"max_depth\": hp.quniform('max_depth', 2, 8, 2),\n",
    "    \"n_estimators\": hp.quniform('n_estimators', 50, 200, 4)\n",
    "}\n",
    "\n",
    "# 2. The objective\n",
    "def objective(params):\n",
    "    params = {\n",
    "        \"max_depth\": int(params[\"max_depth\"]),\n",
    "        \"n_estimators\": int(params[\"n_estimators\"])}\n",
    "    rf = RandomForestClassifier(**params) \n",
    "    best_score = cross_val_score(rf, X_train, y_train, scoring=\"accuracy\", cv=2, n_jobs=-1).mean()\n",
    "    \n",
    "    # hyperopt minimizes the function, which is why we return the loss and not the best score\n",
    "    # (lower loss is better)\n",
    "    loss = 1 - best_score\n",
    "    return loss\n",
    "\n",
    "# Then we need to run the optimization function\n",
    "best = fmin(fn=objective, space=space, max_evals=20, rstate=np.random.RandomState(42), algo=tpe.suggest)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Hyperparameter Tuning with TPOT\n",
    "\n",
    "References:\n",
    "\n",
    "* [Hyperparameter Tuning in Python](https://campus.datacamp.com/courses/hyperparameter-tuning-in-python/informed-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=58.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7197090390742915\n",
      "Generation 2 - Current best internal CV score: 0.7252920789311867\n",
      "Generation 3 - Current best internal CV score: 0.7252920789311867\n",
      "Generation 4 - Current best internal CV score: 0.7252920789311867\n",
      "Generation 5 - Current best internal CV score: 0.7252920789311867\n",
      "Generation 6 - Current best internal CV score: 0.7252920789311867\n",
      "Generation 7 - Current best internal CV score: 0.7290723349544412\n",
      "Generation 8 - Current best internal CV score: 0.7290723349544412\n",
      "Generation 9 - Current best internal CV score: 0.7439977080887696\n",
      "Generation 10 - Current best internal CV score: 0.7439977080887696\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=False, criterion=entropy, max_features=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(cv=2, generations=10,\n",
       "               log_file=<ipykernel.iostream.OutStream object at 0x1072a9460>,\n",
       "               offspring_size=5, population_size=8, random_state=2,\n",
       "               scoring='accuracy', verbosity=2)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"TPOT is quite unstable when only running with low generations, population size and offspring.\n",
    "# Increasing the generations, population size and offspring and running this for a long \n",
    "# time will assist to produce better models and more stable results.\"\n",
    "tpot_clf = TPOTClassifier(generations=10, population_size=8, offspring_size=5, \n",
    "                            scoring=\"accuracy\", verbosity=2, random_state=2, cv=2)\n",
    "\n",
    "tpot_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
